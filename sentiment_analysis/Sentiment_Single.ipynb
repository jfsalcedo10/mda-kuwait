{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d34a5a3c",
   "metadata": {},
   "source": [
    "# Group 1 - Sentiment Analysis \n",
    "   \n",
    "**⛳️ Goal**: Analyzing the sentiments of the speeches using an unsupervised machine learning technique.\n",
    "<br>\n",
    "<font color= 'red'> ***To-Do***\n",
    "* Make a class that can loop the following functions for all the speech files.\n",
    "* Check whether these are correctly done.\n",
    "* Which method is best for us? (Need to learn more about the methods..)\n",
    "</br> \n",
    "\n",
    "<br>\n",
    "\n",
    "***Note***\n",
    "* Based on the reference link, `Stanza` pipeline seems better than `TextBlob` for our case. Although TextBlob can portray some nuance of the text due to its scale [-1,1], for a longer text it is better to use `Stanza`.  (See: http://monkeythinkmonkeycode.com/nlp-in-python-a-quick-library-comparison-for-sentiment-analysis/)\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c95aa",
   "metadata": {},
   "source": [
    "<h2> Getting PDFs </h2>\n",
    "\n",
    "* Used Jolien's codes\n",
    "* Used only \"Farewell_to_Staff_and_Supporters.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "964e5057",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:36:48.293462Z",
     "start_time": "2022-05-03T12:36:48.283870Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pdfplumber\n",
    "import re\n",
    "\n",
    "import sys\n",
    "src_path = str(Path.cwd().parent / \"pdfs\")\n",
    "sys.path.append(src_path)\n",
    "\n",
    "\n",
    "src_path = str(Path.cwd().parent / \"src\")\n",
    "sys.path.append(src_path)\n",
    "from pdf_processing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057a62c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:32:40.049279Z",
     "start_time": "2022-05-03T12:32:39.329910Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4bbde7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:36:56.843704Z",
     "start_time": "2022-05-03T12:36:56.836424Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current number of PDFs: 4\n"
     ]
    }
   ],
   "source": [
    "pdf_dir = Path.cwd().parent / \"pdfs\"\n",
    "pdfs = list(pdf_dir.glob('*.pdf'))  \n",
    "print(\"current number of PDFs:\", len(pdfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73e69f2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:36:58.346491Z",
     "start_time": "2022-05-03T12:36:58.338985Z"
    }
   },
   "outputs": [],
   "source": [
    "filepath = pdfs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75ff0bb7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:36:59.731951Z",
     "start_time": "2022-05-03T12:36:59.724756Z"
    }
   },
   "outputs": [],
   "source": [
    "pdf = PDFHandler(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f27aee0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:37:36.330224Z",
     "start_time": "2022-05-03T12:37:35.367112Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michelle and I, we've really been milking this goodbye thing, so it behooves me to be very \n",
      " \n",
      "brief.\n",
      "Audience Members: No, no!  \n",
      "President Obama: Yes, yes.  \n",
      "You know, I said before and I will say again, that when we started on this journey we did so \n",
      "with an abiding faith in the American people and their ability, out ability, to join together to \n",
      "change the country in ways that would make life better for our kids and our grandkids, that \n",
      " \n",
      "change didn’t happen from the top down, but it happened from the bottom up.\n",
      "It was met sometimes with skepticism and doubt. Some folks didn’t think we could pull it off. \n",
      "There were those who felt that the institutions of power and privilege in this country were too \n",
      " \n",
      "deeply entrenched. And yet, all of you came together, in small towns and big cities, a whole bunch of you really \n",
      "young, and you decided to believe. And you knocked on doors and you made phone calls, and \n",
      "you talked to your parents who didn’t know how to pronounce Barack Obama. And you got to \n",
      "know each other. And you went into communities that maybe you’d never even thought about \n",
      "visiting. And met people that on the surface seemed completely different than you -- who \n",
      "didn’t look like you or talk like you or watch the same TV programs as you. And yet, once you \n",
      " \n",
      "started talking to them, it turned out that you had something in common.\n",
      " \n",
      "And it grew, and it built.\n",
      "And people took notice. And throughout, it was infused with a sense of hope. And as I said in \n",
      "2004, it wasn’t blind optimism that drove you to do all this work. It wasn’t naïveté. It wasn’t \n",
      "willful ignorance to all the challenges that America faces. It was hope in the face of difficulty, \n",
      " \n",
      "hope in the face of uncertainty.\n",
      " \n",
      "You proved the power of hope. \n",
      "And throughout this process, Michelle and I -- we’ve just been your frontmen and women. We \n",
      "have been the face, sometimes the voice, out front on the TV screen or in front of the \n",
      " \n",
      "microphone. But this has never been about us. It has always been about you.\n",
      "And all the amazing things that happened over these last 10 years are really just a testament \n",
      "to you -- in the same way that when we talk about our amazing military and our men and \n",
      "women in uniform. The -- The military’s not a thing. It’s a group of committed patriots willing \n",
      "to sacrifice everything on our behalf. It works only because of the people in it. As -- As cool as \n",
      "the hardware is -- and we’ve got cool hardware -- as cool as the machines, weapons, and \n",
      "satellites are, ultimately it comes down to remarkable people, some of them a lot closer to \n",
      " \n",
      "Malia’s age than -- than mine or Michelle’s.\n",
      "Well the same thing’s true for our democracy. Our democracy’s not the buildings; it’s not the \n",
      "monuments; it’s you being willing to work to make things better, and being willing to listen to \n",
      "each other and argue with each other and come together and knock on doors and make phone \n",
      " \n",
      "calls and treat people with respect.\n",
      " \n",
      "And that doesn’t end. This is just a -- just a little old pit stop.\n",
      " \n",
      "This...is not a period. This is a comma in the continuing story of building America. So to all of you that have put your heart and soul, not just into our campaigns but into \n",
      "making schools better; making sure our veterans got the care they needed; making sure that \n",
      "we left behind a planet that is safe and secure for our kids; making sure that hardworking \n",
      " \n",
      "people have a ladder of opportunity that supports families.\n",
      "For -- For all of you who have just done amazing, remarkable work, most of it unheralded, \n",
      "most of it without fanfare, most of it without you getting any word of thanks, we could not be \n",
      "prouder of you. I could not be prouder. This has been the privilege of my life, and I know I \n",
      " \n",
      "speak for Michelle as well. \n",
      "And you know, we look forward to continuing this journey with all of you; and I can’t wait to \n",
      " \n",
      "see what you do next.\n",
      " \n",
      "And I promise you, I’ll be right here with you. \n",
      " \n",
      "All right?\n",
      " \n",
      "God bless you. Thank you, everybody.\n",
      " \n",
      "Yes we did. Yes we can.\n",
      " \n",
      "God bless America.\n"
     ]
    }
   ],
   "source": [
    "start = r\"(?:hheettoorriicc\\.\\.ccoomm)\"\n",
    "date = r\"(.*[dD]elivered\\s+(?P<day>[0-9]{1,2})\\s+(?P<mon>[A-Z][a-z]+)\\s+(?P<year>[0-9]{2,4})\"\n",
    "loc = r\"(,\\s+(?P<location_small>[A-Za-z0-9. ]+),\\s+(?P<location_big>[A-Za-z0-9., ]+))?\"\n",
    "auth = r\"(?:\\s+AUTHENTICITY CERTIFIED: Text version below transcribed directly from audio))?\"\n",
    "content = r\"\\s+(?P<content>.*)\\n+\"\n",
    "end = r\"(?:(Transcription\\s+by\\s+.*)?(Property\\s+of\\s+)?AmericanRhetoric\\.com)\"\n",
    "\n",
    "pat = re.compile(start + date + loc + auth + content + end, re.DOTALL)\n",
    "\n",
    "speech = pdf.extract_speech(pat)\n",
    "print(speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ca0dbab",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:37:50.050840Z",
     "start_time": "2022-05-03T12:37:50.046114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Farewell_to_Staff_and_Supporters\n",
      "Number of pages: 3\n",
      "Date: ['20', 'January', '2017']\n",
      "Location: ['Prince George County', 'Maryland']\n"
     ]
    }
   ],
   "source": [
    "pdf.print_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf543e9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:37:56.858003Z",
     "start_time": "2022-05-03T12:37:56.849526Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michelle and I, we've really been milking this goodbye thing, so it behooves me to be very brief. Audience Members: No, no! President Obama: Yes, yes. You know, I said before and I will say again, that when we started on this journey we did so with an abiding faith in the American people and their ability, out ability, to join together to change the country in ways that would make life better for our kids and our grandkids, that change didn't happen from the top down, but it happened from the bottom up. It was met sometimes with skepticism and doubt. Some folks didn't think we could pull it off. There were those who felt that the institutions of power and privilege in this country were too deeply entrenched. And yet, all of you came together, in small towns and big cities, a whole bunch of you really young, and you decided to believe. And you knocked on doors and you made phone calls, and you talked to your parents who didn't know how to pronounce Barack Obama. And you got to know each other. And you went into communities that maybe you'd never even thought about visiting. And met people that on the surface seemed completely different than you who didn't look like you or talk like you or watch the same TV programs as you. And yet, once you started talking to them, it turned out that you had something in common. And it grew, and it built. And people took notice. And throughout, it was infused with a sense of hope. And as I said in 2004, it wasn't blind optimism that drove you to do all this work. It wasn't naïveté. It wasn't willful ignorance to all the challenges that America faces. It was hope in the face of difficulty, hope in the face of uncertainty. You proved the power of hope. And throughout this process, Michelle and I we've just been your frontmen and women. We have been the face, sometimes the voice, out front on the TV screen or in front of the microphone. But this has never been about us. It has always been about you. And all the amazing things that happened over these last 10 years are really just a testament to you in the same way that when we talk about our amazing military and our men and women in uniform. The The military's not a thing. It's a group of committed patriots willing to sacrifice everything on our behalf. It works only because of the people in it. As As cool as the hardware is and we've got cool hardware as cool as the machines, weapons, and satellites are, ultimately it comes down to remarkable people, some of them a lot closer to Malia's age than than mine or Michelle's. Well the same thing's true for our democracy. Our democracy's not the buildings; it's not the monuments; it's you being willing to work to make things better, and being willing to listen to each other and argue with each other and come together and knock on doors and make phone calls and treat people with respect. And that doesn't end. This is just a just a little old pit stop. This is not a period. This is a comma in the continuing story of building America. So to all of you that have put your heart and soul, not just into our campaigns but into making schools better; making sure our veterans got the care they needed; making sure that we left behind a planet that is safe and secure for our kids; making sure that hardworking people have a ladder of opportunity that supports families. For For all of you who have just done amazing, remarkable work, most of it unheralded, most of it without fanfare, most of it without you getting any word of thanks, we could not be prouder of you. I could not be prouder. This has been the privilege of my life, and I know I speak for Michelle as well. And you know, we look forward to continuing this journey with all of you; and I can't wait to see what you do next. And I promise you, I'll be right here with you. All right? God bless you. Thank you, everybody. Yes we did. Yes we can. God bless America.\n"
     ]
    }
   ],
   "source": [
    "old = [r'-+', r'\\.{2,}', r'[’‘]', r'\"', r'’’', r'‘‘', r'“', r'”', r',', r'\\[sic\\]', r'\\s+']\n",
    "new = [r' ' , r' '     , r\"'\"   , r'' , r''  , r''  , r'' , r'' , r',', r' '      , r' '  ]\n",
    "\n",
    "clean_speech = pdf.replace(speech, old, new)\n",
    "print(clean_speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e457ba",
   "metadata": {},
   "source": [
    "<h2> Preprocessing </h2>\n",
    "\n",
    "Note that these are just individual codes that are possible for each purpose. These steps are not necessary for `Stanza` since it offers a pipeline in which you can do the processing and sentiment analysis all at the same time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b556c4",
   "metadata": {},
   "source": [
    "<h3> Tokenization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2d53414f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T13:03:03.941391Z",
     "start_time": "2022-05-03T13:03:03.938093Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize , word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef04b0dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T13:15:07.742669Z",
     "start_time": "2022-05-03T13:15:07.735001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"Michelle and I, we've really been milking this goodbye thing, so it behooves me to be very brief.\", 'Audience Members: No, no!', 'President Obama: Yes, yes.', \"You know, I said before and I will say again, that when we started on this journey we did so with an abiding faith in the American people and their ability, out ability, to join together to change the country in ways that would make life better for our kids and our grandkids, that change didn't happen from the top down, but it happened from the bottom up.\"]\n"
     ]
    }
   ],
   "source": [
    "sentence = nltk.sent_tokenize(clean_speech)\n",
    "print(sentence[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "848af685",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T13:15:48.682278Z",
     "start_time": "2022-05-03T13:15:48.676873Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Michelle', 'and', 'I', ',', 'we', \"'ve\", 'really', 'been', 'milking', 'this', 'goodbye', 'thing', ',', 'so', 'it', 'behooves', 'me', 'to', 'be', 'very', 'brief', '.']\n"
     ]
    }
   ],
   "source": [
    "words_1 = word_tokenize(sentence[0])\n",
    "print(words_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecee6ec",
   "metadata": {},
   "source": [
    "<h3> Lemmatization </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "283779e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T13:13:27.185796Z",
     "start_time": "2022-05-03T13:13:27.175975Z"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "36d5e211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T13:14:35.900988Z",
     "start_time": "2022-05-03T13:14:35.896763Z"
    }
   },
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7c29c794",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T13:16:43.778072Z",
     "start_time": "2022-05-03T13:16:43.774142Z"
    }
   },
   "outputs": [],
   "source": [
    "word_list = []\n",
    "for w in words_1: #loop over the first sentence\n",
    "    word_list.append((w,wordnet_lemmatizer.lemmatize(w))) \n",
    "    #take every word and lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "62abc830",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T13:17:02.092290Z",
     "start_time": "2022-05-03T13:17:02.081396Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Michelle', 'Michelle'),\n",
       " ('and', 'and'),\n",
       " ('I', 'I'),\n",
       " (',', ','),\n",
       " ('we', 'we'),\n",
       " (\"'ve\", \"'ve\"),\n",
       " ('really', 'really'),\n",
       " ('been', 'been'),\n",
       " ('milking', 'milking'),\n",
       " ('this', 'this'),\n",
       " ('goodbye', 'goodbye'),\n",
       " ('thing', 'thing'),\n",
       " (',', ','),\n",
       " ('so', 'so'),\n",
       " ('it', 'it'),\n",
       " ('behooves', 'behooves'),\n",
       " ('me', 'me'),\n",
       " ('to', 'to'),\n",
       " ('be', 'be'),\n",
       " ('very', 'very'),\n",
       " ('brief', 'brief'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ffbca2",
   "metadata": {},
   "source": [
    "<h2> Stanza Pipeline </h2>\n",
    "\n",
    "Mainly followed codes provided by Stanza documentation: <a> https://stanfordnlp.github.io/stanza/ </a>.\n",
    "<br> This allows us to **tokenize & lemmatize** all at the same time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c487f210",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T15:45:42.794398Z",
     "start_time": "2022-05-03T15:45:05.257214Z"
    }
   },
   "outputs": [],
   "source": [
    "import stanza\n",
    "stanza.download('en',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ac053352",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T17:18:08.209078Z",
     "start_time": "2022-05-03T17:18:05.994201Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline('en', processors='tokenize, mwt, pos, lemma, depparse,sentiment',\n",
    "                      use_gpu=False, \n",
    "                      verbose=False, pos_batch_size=3000) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cc8b35",
   "metadata": {},
   "source": [
    "Use Stanza Pipeline to do both tokenization & sentiment analysis for our first text file.\n",
    "Sentiment Levels:\n",
    "* Negative = 0 \n",
    "* Neutral = 1\n",
    "* Positive = 2\n",
    "<br>\n",
    "Note: \"Sentiment is added to the stanza pipeline by using a CNN classifier\". (Convolutional Neural Networks: <a>https://arxiv.org/abs/1408.5882 </a>) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c10ad7a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T16:43:30.901662Z",
     "start_time": "2022-05-03T16:43:25.546577Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 0\n",
      "2 1\n",
      "3 1\n",
      "4 2\n",
      "5 1\n",
      "6 0\n",
      "7 0\n",
      "8 1\n",
      "9 0\n",
      "10 1\n",
      "11 0\n",
      "12 0\n",
      "13 1\n",
      "14 1\n",
      "15 1\n",
      "16 2\n",
      "17 0\n",
      "18 0\n",
      "19 0\n",
      "20 1\n",
      "21 1\n",
      "22 1\n",
      "23 1\n",
      "24 0\n",
      "25 1\n",
      "26 2\n",
      "27 1\n",
      "28 1\n",
      "29 1\n",
      "30 2\n",
      "31 1\n",
      "32 0\n",
      "33 0\n",
      "34 1\n",
      "35 1\n",
      "36 1\n",
      "37 2\n",
      "38 1\n",
      "39 2\n",
      "40 0\n",
      "41 1\n",
      "42 1\n",
      "43 1\n",
      "44 1\n",
      "45 1\n",
      "46 1\n",
      "47 1\n",
      "48 1\n",
      "49 1\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(clean_speech)\n",
    "\n",
    "doc_sent = []\n",
    "for i, sentence in enumerate(doc.sentences):\n",
    "    print(i, sentence.sentiment)\n",
    "    doc_sent.append(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ef327c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T16:43:34.339580Z",
     "start_time": "2022-05-03T16:43:34.322842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Average of the sentiment values\n",
    "sum(doc_sent)/len(doc_sent) #0.86 = Rather neutral?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2530fc92",
   "metadata": {},
   "source": [
    "<h2> TextBlob </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1f6aa9de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T21:31:45.645241Z",
     "start_time": "2022-05-03T21:31:45.619391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.1824178501810081, subjectivity=0.48478139793929265)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1824178501810081"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tb_speech = TextBlob(clean_speech)\n",
    "print(tb_speech.sentiment)\n",
    "tb_speech.polarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08038973",
   "metadata": {},
   "source": [
    "<h3> Stanza vs. TextBlob  </h3> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "540bc09d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T21:39:28.509859Z",
     "start_time": "2022-05-03T21:39:26.999233Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment',verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "449e7918",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T21:49:46.545624Z",
     "start_time": "2022-05-03T21:49:46.539476Z"
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "cba4a9c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T21:50:27.801464Z",
     "start_time": "2022-05-03T21:50:27.794595Z"
    }
   },
   "outputs": [],
   "source": [
    "sentence = nltk.sent_tokenize(clean_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9063014c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T21:52:03.437358Z",
     "start_time": "2022-05-03T21:52:03.406108Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\" Michelle I , 've really milking goodbye thing , behooves brief .\",\n",
       " ' Audience Members : No , !',\n",
       " ' President Obama : Yes , yes .',\n",
       " \" You know , I said I say , started journey abiding faith American people ability , ability , join together change country ways would make life better kids grandkids , change n't happen top , happened bottom .\",\n",
       " ' It met sometimes skepticism doubt .',\n",
       " \" Some folks n't think could pull .\",\n",
       " ' There felt institutions power privilege country deeply entrenched .',\n",
       " ' And yet , came together , small towns big cities , whole bunch really young , decided believe .',\n",
       " \" And knocked doors made phone calls , talked parents n't know pronounce Barack Obama .\",\n",
       " ' And got know .',\n",
       " \" And went communities maybe 'd never even thought visiting .\",\n",
       " \" And met people surface seemed completely different n't look like talk like watch TV programs .\",\n",
       " ' And yet , started talking , turned something common .',\n",
       " ' And grew , built .',\n",
       " ' And people took notice .',\n",
       " ' And throughout , infused sense hope .',\n",
       " \" And I said 2004 , n't blind optimism drove work .\",\n",
       " \" It n't naïveté .\",\n",
       " \" It n't willful ignorance challenges America faces .\",\n",
       " ' It hope face difficulty , hope face uncertainty .',\n",
       " ' You proved power hope .',\n",
       " \" And throughout process , Michelle I 've frontmen women .\",\n",
       " ' We face , sometimes voice , front TV screen front microphone .',\n",
       " ' But never us .',\n",
       " ' It always .',\n",
       " ' And amazing things happened last 10 years really testament way talk amazing military men women uniform .',\n",
       " \" The The military 's thing .\",\n",
       " \" It 's group committed patriots willing sacrifice everything behalf .\",\n",
       " ' It works people .',\n",
       " \" As As cool hardware 've got cool hardware cool machines , weapons , satellites , ultimately comes remarkable people , lot closer Malia 's age mine Michelle 's .\",\n",
       " \" Well thing 's true democracy .\",\n",
       " \" Our democracy 's buildings ; 's monuments ; 's willing work make things better , willing listen argue come together knock doors make phone calls treat people respect .\",\n",
       " \" And n't end .\",\n",
       " ' This little old pit stop .',\n",
       " ' This period .',\n",
       " ' This comma continuing story building America .',\n",
       " ' So put heart soul , campaigns making schools better ; making sure veterans got care needed ; making sure left behind planet safe secure kids ; making sure hardworking people ladder opportunity supports families .',\n",
       " ' For For done amazing , remarkable work , unheralded , without fanfare , without getting word thanks , could prouder .',\n",
       " ' I could prouder .',\n",
       " ' This privilege life , I know I speak Michelle well .',\n",
       " \" And know , look forward continuing journey ; I ca n't wait see next .\",\n",
       " \" And I promise , I 'll right .\",\n",
       " ' All right ?',\n",
       " ' God bless .',\n",
       " ' Thank , everybody .',\n",
       " ' Yes .',\n",
       " ' Yes .',\n",
       " ' God bless America .']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speech = []\n",
    "\n",
    "for sent in sentence:\n",
    "    word_tokens = word_tokenize(sent)  \n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words]  \n",
    "    x = ''\n",
    "    for word in filtered_sentence:\n",
    "        x +=' '+word\n",
    "    df_speech.append(x)\n",
    "    \n",
    "df_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "ddec2d83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T22:13:56.517880Z",
     "start_time": "2022-05-03T22:13:56.509370Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df_speech)\n",
    "df.columns = ['text']\n",
    "\n",
    "df['sentiment_stanza']=''\n",
    "df['sentiment_blob'] = ''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d4fe4338",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T22:13:57.024793Z",
     "start_time": "2022-05-03T22:13:57.017310Z"
    }
   },
   "outputs": [],
   "source": [
    "def blob_sentiment(txt):\n",
    "    sent = TextBlob(txt).sentiment.polarity\n",
    "    return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "941da829",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T22:13:57.529253Z",
     "start_time": "2022-05-03T22:13:57.508637Z"
    }
   },
   "outputs": [],
   "source": [
    "df['sentiment_blob'] = df['text'].apply(lambda x: blob_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "518c3418",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T22:13:59.962100Z",
     "start_time": "2022-05-03T22:13:57.952153Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,sentiment')\n",
    "for idx in df.index:\n",
    "    doc = nlp(df.loc[idx,'text'])\n",
    "    for i, sentence in enumerate(doc.sentences):\n",
    "        df.loc[idx,'sentiment_stanza']=np.float_(sentence.sentiment-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "8b20a57f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T22:14:00.209842Z",
     "start_time": "2022-05-03T22:14:00.189947Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment_stanza</th>\n",
       "      <th>sentiment_blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Michelle I , 've really milking goodbye thing...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Audience Members : No , !</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>President Obama : Yes , yes .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You know , I said I say , started journey abi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It met sometimes skepticism doubt .</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text sentiment_stanza  \\\n",
       "0   Michelle I , 've really milking goodbye thing...              0.0   \n",
       "1                          Audience Members : No , !             -1.0   \n",
       "2                      President Obama : Yes , yes .              0.0   \n",
       "3   You know , I said I say , started journey abi...              0.0   \n",
       "4                It met sometimes skepticism doubt .              0.0   \n",
       "\n",
       "   sentiment_blob  \n",
       "0        0.100000  \n",
       "1        0.000000  \n",
       "2        0.000000  \n",
       "3        0.333333  \n",
       "4        0.000000  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1f1ad0",
   "metadata": {},
   "source": [
    "<h2> Vader on the entire speech </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95eb1490",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:40:48.237100Z",
     "start_time": "2022-05-03T12:40:43.657135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 KB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/serenekim/opt/anaconda3/lib/python3.9/site-packages (from vaderSentiment) (2.26.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/serenekim/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/serenekim/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/serenekim/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/serenekim/opt/anaconda3/lib/python3.9/site-packages (from requests->vaderSentiment) (2.0.4)\n",
      "Installing collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.3.2\n"
     ]
    }
   ],
   "source": [
    "# install vader if not already available\n",
    "# !pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa00d09e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T16:14:43.708212Z",
     "start_time": "2022-05-03T16:14:43.677432Z"
    }
   },
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b27bc095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T16:14:44.359325Z",
     "start_time": "2022-05-03T16:14:44.349880Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_analyzer_scores(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    print(\"{:-<40} {}\".format(sentence, str(score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aea1f608",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-03T12:45:08.076619Z",
     "start_time": "2022-05-03T12:45:08.008927Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Michelle and I, we've really been milking this goodbye thing, so it behooves me to be very brief. Audience Members: No, no! President Obama: Yes, yes. You know, I said before and I will say again, that when we started on this journey we did so with an abiding faith in the American people and their ability, out ability, to join together to change the country in ways that would make life better for our kids and our grandkids, that change didn't happen from the top down, but it happened from the bottom up. It was met sometimes with skepticism and doubt. Some folks didn't think we could pull it off. There were those who felt that the institutions of power and privilege in this country were too deeply entrenched. And yet, all of you came together, in small towns and big cities, a whole bunch of you really young, and you decided to believe. And you knocked on doors and you made phone calls, and you talked to your parents who didn't know how to pronounce Barack Obama. And you got to know each other. And you went into communities that maybe you'd never even thought about visiting. And met people that on the surface seemed completely different than you who didn't look like you or talk like you or watch the same TV programs as you. And yet, once you started talking to them, it turned out that you had something in common. And it grew, and it built. And people took notice. And throughout, it was infused with a sense of hope. And as I said in 2004, it wasn't blind optimism that drove you to do all this work. It wasn't naïveté. It wasn't willful ignorance to all the challenges that America faces. It was hope in the face of difficulty, hope in the face of uncertainty. You proved the power of hope. And throughout this process, Michelle and I we've just been your frontmen and women. We have been the face, sometimes the voice, out front on the TV screen or in front of the microphone. But this has never been about us. It has always been about you. And all the amazing things that happened over these last 10 years are really just a testament to you in the same way that when we talk about our amazing military and our men and women in uniform. The The military's not a thing. It's a group of committed patriots willing to sacrifice everything on our behalf. It works only because of the people in it. As As cool as the hardware is and we've got cool hardware as cool as the machines, weapons, and satellites are, ultimately it comes down to remarkable people, some of them a lot closer to Malia's age than than mine or Michelle's. Well the same thing's true for our democracy. Our democracy's not the buildings; it's not the monuments; it's you being willing to work to make things better, and being willing to listen to each other and argue with each other and come together and knock on doors and make phone calls and treat people with respect. And that doesn't end. This is just a just a little old pit stop. This is not a period. This is a comma in the continuing story of building America. So to all of you that have put your heart and soul, not just into our campaigns but into making schools better; making sure our veterans got the care they needed; making sure that we left behind a planet that is safe and secure for our kids; making sure that hardworking people have a ladder of opportunity that supports families. For For all of you who have just done amazing, remarkable work, most of it unheralded, most of it without fanfare, most of it without you getting any word of thanks, we could not be prouder of you. I could not be prouder. This has been the privilege of my life, and I know I speak for Michelle as well. And you know, we look forward to continuing this journey with all of you; and I can't wait to see what you do next. And I promise you, I'll be right here with you. All right? God bless you. Thank you, everybody. Yes we did. Yes we can. God bless America. {'neg': 0.04, 'neu': 0.765, 'pos': 0.196, 'compound': 0.9992}\n"
     ]
    }
   ],
   "source": [
    "sentiment_analyzer_scores(clean_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df15c30e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
