{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b11df643",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex, re, sys, nltk\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "from gensim.models.hdpmodel import HdpModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "src_path = str(Path.cwd().parent / \"src\")\n",
    "sys.path.append(src_path)\n",
    "# python file with all the functions (located in the src folder)\n",
    "import topic_classification as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2d51934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CGI_2013</td>\n",
       "      <td>Hillary Clinton: Thank you very much. I have t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prayer_Breakfast_2016</td>\n",
       "      <td>Well, good morning. Giving all praise and hono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Security_Team_Announcement</td>\n",
       "      <td>Good morning, everybody. I hope you all had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cairo_University</td>\n",
       "      <td>Thank you so much. Good afternoon. I am honore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Umpqua_Community_College_Shootings</td>\n",
       "      <td>There's been another mass shooting in America ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                            CGI_2013   \n",
       "1               Prayer_Breakfast_2016   \n",
       "2          Security_Team_Announcement   \n",
       "3                    Cairo_University   \n",
       "4  Umpqua_Community_College_Shootings   \n",
       "\n",
       "                                             content  \n",
       "0  Hillary Clinton: Thank you very much. I have t...  \n",
       "1  Well, good morning. Giving all praise and hono...  \n",
       "2  Good morning, everybody. I hope you all had a ...  \n",
       "3  Thank you so much. Good afternoon. I am honore...  \n",
       "4  There's been another mass shooting in America ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = Path.cwd().parent / \"speeches_csv\" / \"all_speeches_cleaned.txt\"\n",
    "df=pd.read_csv(filepath, usecols=['title','content'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a51a4b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CGI_2013</td>\n",
       "      <td>Hillary Clinton: Thank you very much. I have t...</td>\n",
       "      <td>hillary clinton: thank you very much. i have t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Prayer_Breakfast_2016</td>\n",
       "      <td>Well, good morning. Giving all praise and hono...</td>\n",
       "      <td>well, good morning. giving all praise and hono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Security_Team_Announcement</td>\n",
       "      <td>Good morning, everybody. I hope you all had a ...</td>\n",
       "      <td>good morning, everybody. i hope you all had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cairo_University</td>\n",
       "      <td>Thank you so much. Good afternoon. I am honore...</td>\n",
       "      <td>thank you so much. good afternoon. i am honore...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Umpqua_Community_College_Shootings</td>\n",
       "      <td>There's been another mass shooting in America ...</td>\n",
       "      <td>there's been another mass shooting in america ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                title  \\\n",
       "0                            CGI_2013   \n",
       "1               Prayer_Breakfast_2016   \n",
       "2          Security_Team_Announcement   \n",
       "3                    Cairo_University   \n",
       "4  Umpqua_Community_College_Shootings   \n",
       "\n",
       "                                             content  \\\n",
       "0  Hillary Clinton: Thank you very much. I have t...   \n",
       "1  Well, good morning. Giving all praise and hono...   \n",
       "2  Good morning, everybody. I hope you all had a ...   \n",
       "3  Thank you so much. Good afternoon. I am honore...   \n",
       "4  There's been another mass shooting in America ...   \n",
       "\n",
       "                                                text  \n",
       "0  hillary clinton: thank you very much. i have t...  \n",
       "1  well, good morning. giving all praise and hono...  \n",
       "2  good morning, everybody. i hope you all had a ...  \n",
       "3  thank you so much. good afternoon. i am honore...  \n",
       "4  there's been another mass shooting in america ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text']=df['content'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09fe5f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hillary clinton: thank you very much. i have t...</td>\n",
       "      <td>[hillary clinton: thank you very much., i have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well, good morning. giving all praise and hono...</td>\n",
       "      <td>[well, good morning., giving all praise and ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good morning, everybody. i hope you all had a ...</td>\n",
       "      <td>[good morning, everybody., i hope you all had ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank you so much. good afternoon. i am honore...</td>\n",
       "      <td>[thank you so much., good afternoon., i am hon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there's been another mass shooting in america ...</td>\n",
       "      <td>[there's been another mass shooting in america...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  hillary clinton: thank you very much. i have t...   \n",
       "1  well, good morning. giving all praise and hono...   \n",
       "2  good morning, everybody. i hope you all had a ...   \n",
       "3  thank you so much. good afternoon. i am honore...   \n",
       "4  there's been another mass shooting in america ...   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [hillary clinton: thank you very much., i have...  \n",
       "1  [well, good morning., giving all praise and ho...  \n",
       "2  [good morning, everybody., i hope you all had ...  \n",
       "3  [thank you so much., good afternoon., i am hon...  \n",
       "4  [there's been another mass shooting in america...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenize into sentences\n",
    "df['tokenized']=df['text'].apply(lambda text: nltk.sent_tokenize(text))\n",
    "df[['text','tokenized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "288d9fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hillary clinton: thank you very much. i have t...</td>\n",
       "      <td>[hillary clinton: thank you very much., i have...</td>\n",
       "      <td>hillary clinton thank you very much i have th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well, good morning. giving all praise and hono...</td>\n",
       "      <td>[well, good morning., giving all praise and ho...</td>\n",
       "      <td>well good morning give all praise and honor t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good morning, everybody. i hope you all had a ...</td>\n",
       "      <td>[good morning, everybody., i hope you all had ...</td>\n",
       "      <td>good morning everybody i hope you all have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank you so much. good afternoon. i am honore...</td>\n",
       "      <td>[thank you so much., good afternoon., i am hon...</td>\n",
       "      <td>thank you so much good afternoon i be honor t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there's been another mass shooting in america ...</td>\n",
       "      <td>[there's been another mass shooting in america...</td>\n",
       "      <td>there s be another mass shooting in america t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  hillary clinton: thank you very much. i have t...   \n",
       "1  well, good morning. giving all praise and hono...   \n",
       "2  good morning, everybody. i hope you all had a ...   \n",
       "3  thank you so much. good afternoon. i am honore...   \n",
       "4  there's been another mass shooting in america ...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [hillary clinton: thank you very much., i have...   \n",
       "1  [well, good morning., giving all praise and ho...   \n",
       "2  [good morning, everybody., i hope you all had ...   \n",
       "3  [thank you so much., good afternoon., i am hon...   \n",
       "4  [there's been another mass shooting in america...   \n",
       "\n",
       "                                          normalized  \n",
       "0   hillary clinton thank you very much i have th...  \n",
       "1   well good morning give all praise and honor t...  \n",
       "2   good morning everybody i hope you all have a ...  \n",
       "3   thank you so much good afternoon i be honor t...  \n",
       "4   there s be another mass shooting in america t...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the '\\b(?!\\d)' filters out expressions like '9th', since the first character cannot be a number\n",
    "tokenizer = RegexpTokenizer(r'\\b(?!\\d)[a-zA-Z]+')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "df['normalized']=df['tokenized'].apply(lambda text: tc.normalize_text(text, tokenizer, lemmatizer))\n",
    "df[['text','tokenized','normalized']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17168b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>normalized</th>\n",
       "      <th>fully_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hillary clinton: thank you very much. i have t...</td>\n",
       "      <td>[hillary clinton: thank you very much., i have...</td>\n",
       "      <td>hillary clinton thank you very much i have th...</td>\n",
       "      <td>hillary clinton pleasure introduce speaker con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>well, good morning. giving all praise and hono...</td>\n",
       "      <td>[well, good morning., giving all praise and ho...</td>\n",
       "      <td>well good morning give all praise and honor t...</td>\n",
       "      <td>morning praise honor god morning everyone orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good morning, everybody. i hope you all had a ...</td>\n",
       "      <td>[good morning, everybody., i hope you all had ...</td>\n",
       "      <td>good morning everybody i hope you all have a ...</td>\n",
       "      <td>morning wonderful thanksgiving announce econom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thank you so much. good afternoon. i am honore...</td>\n",
       "      <td>[thank you so much., good afternoon., i am hon...</td>\n",
       "      <td>thank you so much good afternoon i be honor t...</td>\n",
       "      <td>afternoon honor timeless city cairo host remar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>there's been another mass shooting in america ...</td>\n",
       "      <td>[there's been another mass shooting in america...</td>\n",
       "      <td>there s be another mass shooting in america t...</td>\n",
       "      <td>mass shooting college oregon family mom dad ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  hillary clinton: thank you very much. i have t...   \n",
       "1  well, good morning. giving all praise and hono...   \n",
       "2  good morning, everybody. i hope you all had a ...   \n",
       "3  thank you so much. good afternoon. i am honore...   \n",
       "4  there's been another mass shooting in america ...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  [hillary clinton: thank you very much., i have...   \n",
       "1  [well, good morning., giving all praise and ho...   \n",
       "2  [good morning, everybody., i hope you all had ...   \n",
       "3  [thank you so much., good afternoon., i am hon...   \n",
       "4  [there's been another mass shooting in america...   \n",
       "\n",
       "                                          normalized  \\\n",
       "0   hillary clinton thank you very much i have th...   \n",
       "1   well good morning give all praise and honor t...   \n",
       "2   good morning everybody i hope you all have a ...   \n",
       "3   thank you so much good afternoon i be honor t...   \n",
       "4   there s be another mass shooting in america t...   \n",
       "\n",
       "                                     fully_processed  \n",
       "0  hillary clinton pleasure introduce speaker con...  \n",
       "1  morning praise honor god morning everyone orga...  \n",
       "2  morning wonderful thanksgiving announce econom...  \n",
       "3  afternoon honor timeless city cairo host remar...  \n",
       "4  mass shooting college oregon family mom dad ch...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "df['fully_processed'] = df['normalized'].apply(lambda text: tc.remove_stopwords(text, STOPWORDS))\n",
    "                \n",
    "cnt = Counter()\n",
    "for text in df['fully_processed'].values:\n",
    "    # counts the number of speeches the word is in\n",
    "    for word in set(text.split()):\n",
    "        cnt[word] += 1\n",
    "# words that are in most of the speeches\n",
    "in_most_speeches = cnt.most_common(155)\n",
    "in_most_speeches = [x[0] for x in in_most_speeches]\n",
    "\n",
    "extra = ['mr', 'question', 'sure', 'obama', 'really', 'try', 'lot', 'important', 'million', 'talk', 'va', 'dr', 'romney',\n",
    "        'folk', 'governor', 'republican', 'king', 'heart'] \n",
    "\n",
    "STOPWORDS_extra = set(in_most_speeches + extra)\n",
    "# remove some words from the stopwords list that migth be important\n",
    "STOPWORDS_extra = STOPWORDS_extra - set(['war', 'care', 'child', 'family', 'job', 'law', 'protect', 'security', 'power'])\n",
    "\n",
    "df['fully_processed'] = df['fully_processed'].apply(lambda text: tc.remove_stopwords(text, STOPWORDS_extra))\n",
    "df[['text','tokenized','normalized','fully_processed']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "295b4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [text.split() for text in df['fully_processed'].values]\n",
    "\n",
    "# Create a dictionary\n",
    "# In gensim a dictionary is a mapping between words and their integer id\n",
    "dictionary = Dictionary(texts)\n",
    "\n",
    "# Filter out extremes to limit the number of features\n",
    "dictionary.filter_extremes(\n",
    "    no_below=3,\n",
    "    no_above=0.85,\n",
    "    keep_n=5000\n",
    ")\n",
    "\n",
    "# Create the bag-of-words format (list of (token_id, token_count))\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "Hdp_model = HdpModel(corpus=corpus, id2word=dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09b3d8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.005*job + 0.004*family + 0.004*care + 0.003*economy + 0.003*business + '\n",
      "  '0.003*security + 0.003*health + 0.003*war + 0.003*law + 0.003*child'),\n",
      " (1,\n",
      "  '0.005*must + 0.005*security + 0.004*war + 0.004*nuclear + 0.004*peace + '\n",
      "  '0.003*child + 0.003*job + 0.003*family + 0.003*freedom + 0.003*law'),\n",
      " (2,\n",
      "  '0.005*job + 0.004*economy + 0.004*health + 0.004*business + 0.004*security '\n",
      "  '+ 0.004*iran + 0.004*congress + 0.003*pay + 0.003*care + 0.003*family'),\n",
      " (3,\n",
      "  '0.006*care + 0.006*job + 0.006*health + 0.004*business + 0.004*economy + '\n",
      "  '0.004*system + 0.003*reform + 0.003*tax + 0.003*family + 0.003*pay'),\n",
      " (4,\n",
      "  '0.004*war + 0.004*must + 0.003*security + 0.003*terrorist + 0.003*military '\n",
      "  '+ 0.003*attack + 0.003*isil + 0.003*syria + 0.002*al + 0.002*protect'),\n",
      " (5,\n",
      "  '0.008*gun + 0.005*job + 0.004*health + 0.004*care + 0.004*tax + 0.003*kid + '\n",
      "  '0.003*law + 0.003*system + 0.003*percent + 0.003*family'),\n",
      " (6,\n",
      "  '0.004*family + 0.003*job + 0.003*insurance + 0.003*care + 0.003*health + '\n",
      "  '0.003*cost + 0.002*economy + 0.002*program + 0.002*germany + 0.002*big'),\n",
      " (7,\n",
      "  '0.004*veteran + 0.003*war + 0.003*family + 0.002*military + 0.002*politics '\n",
      "  '+ 0.002*troop + 0.002*myanmar + 0.002*serve + 0.002*point + 0.001*service'),\n",
      " (8,\n",
      "  '0.004*job + 0.003*care + 0.002*family + 0.002*reform + 0.002*vote + '\n",
      "  '0.002*energy + 0.002*child + 0.002*hillary + 0.002*business + 0.002*health'),\n",
      " (9,\n",
      "  '0.006*africa + 0.004*african + 0.003*peace + 0.002*security + 0.002*health '\n",
      "  '+ 0.002*terrorist + 0.002*must + 0.002*problem + 0.002*asean + '\n",
      "  '0.002*intelligence'),\n",
      " (10,\n",
      "  '0.003*isil + 0.002*must + 0.002*europe + 0.002*war + 0.002*russia + '\n",
      "  '0.002*region + 0.002*value + 0.002*israel + 0.002*ideal + 0.002*child'),\n",
      " (11,\n",
      "  '0.005*insurance + 0.004*health + 0.004*care + 0.003*congress + '\n",
      "  '0.003*affordable + 0.003*law + 0.002*job + 0.002*pass + 0.002*economy + '\n",
      "  '0.002*website'),\n",
      " (12,\n",
      "  '0.003*job + 0.003*tax + 0.002*family + 0.002*middle + 0.002*business + '\n",
      "  '0.002*class + 0.002*win + 0.002*economy + 0.002*agreement + 0.002*term'),\n",
      " (13,\n",
      "  '0.002*city + 0.002*mayor + 0.002*action + 0.002*job + 0.002*economy + '\n",
      "  '0.002*global + 0.002*child + 0.002*human + 0.001*war + 0.001*power'),\n",
      " (14,\n",
      "  '0.003*idea + 0.003*health + 0.003*job + 0.003*congressman + 0.003*care + '\n",
      "  '0.002*tax + 0.002*percent + 0.002*budget + 0.002*cost + 0.002*insurance'),\n",
      " (15,\n",
      "  '0.004*drug + 0.004*iran + 0.003*family + 0.002*child + 0.002*treatment + '\n",
      "  '0.002*program + 0.002*care + 0.002*nuclear + 0.002*weak + 0.002*love'),\n",
      " (16,\n",
      "  '0.005*isil + 0.002*syria + 0.002*russia + 0.002*iraq + 0.002*attack + '\n",
      "  '0.002*congress + 0.002*military + 0.002*partner + 0.002*strategy + '\n",
      "  '0.002*point'),\n",
      " (17,\n",
      "  '0.008*veteran + 0.004*job + 0.003*care + 0.003*college + 0.002*war + '\n",
      "  '0.002*family + 0.002*serve + 0.002*service + 0.002*health + 0.002*iraq'),\n",
      " (18,\n",
      "  '0.003*nuclear + 0.002*weapon + 0.002*tax + 0.002*russia + 0.002*gun + '\n",
      "  '0.002*treaty + 0.002*law + 0.002*cut + 0.002*court + 0.001*judge'),\n",
      " (19,\n",
      "  '0.002*climate + 0.002*plan + 0.002*clean + 0.002*power + 0.002*energy + '\n",
      "  '0.002*congress + 0.002*job + 0.001*sustained + 0.001*syria + '\n",
      "  '0.001*pollution')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(Hdp_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15cb662c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
